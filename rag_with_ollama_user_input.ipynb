{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4cb712d-0b4f-4669-b8d1-a6d5e9c7c6f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on: NVIDIA GeForce RTX 2050\n",
      "Done, result on: cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "print(\"Running on:\", torch.cuda.get_device_name(0))\n",
    "\n",
    "# Big tensors to stress test GPU\n",
    "a = torch.rand(5000, 5000, device=device)\n",
    "b = torch.rand(5000, 5000, device=device)\n",
    "\n",
    "# Matrix multiplication on GPU\n",
    "c = torch.matmul(a, b)\n",
    "\n",
    "print(\"Done, result on:\", c.device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "23e4ed4d-e5be-4b54-a679-56b3c4240f27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Choose input type:\n",
      "1. PDF file\n",
      "2. TXT file\n",
      "3. Webpage URL\n",
      "4. Local File Path\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter choice (1-4):  3\n",
      "Enter webpage URL:  https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/PWMJ9-Npq9FYNSWrrf99YQ/watsonx.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n",
      "Failed to send telemetry event ClientCreateCollectionEvent: capture() takes 1 positional argument but 3 were given\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… Sources Loaded: {'webpage': 'https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/PWMJ9-Npq9FYNSWrrf99YQ/watsonx.txt'}\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------\n",
    "# Step 0: Imports\n",
    "# ------------------------------\n",
    "import os\n",
    "import requests\n",
    "from langchain_community.document_loaders import PyPDFLoader, TextLoader, WebBaseLoader\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_core.documents import Document\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain_community.llms import Ollama\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3b889abd-f855-4f07-a0ec-1a9728c73f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------\n",
    "# Step 1: Document Wrapper\n",
    "# ------------------------------\n",
    "class Document:\n",
    "    def __init__(self, metadata, page_content):\n",
    "        self.metadata = metadata\n",
    "        self.page_content = page_content\n",
    "\n",
    "# Dictionary to remember what sources were loaded\n",
    "SOURCES_DICTIONARY = {}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a8c76a-d841-4bb2-8480-c7e805fd5ac3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Choose input type:\n",
      "1. PDF file\n",
      "2. TXT file\n",
      "3. Webpage URL\n",
      "4. Local File Path\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------\n",
    "# Step 2: Load Documents\n",
    "# ------------------------------\n",
    "documents = []\n",
    "\n",
    "print(\"\\nChoose input type:\")\n",
    "print(\"1. PDF file\")\n",
    "print(\"2. TXT file\")\n",
    "print(\"3. Webpage URL\")\n",
    "print(\"4. Local File Path\")\n",
    "choice = input(\"Enter choice (1-4): \")\n",
    "\n",
    "if choice == \"1\":\n",
    "    filepath = input(\"Enter PDF path: \")\n",
    "    loader = PyPDFLoader(filepath)\n",
    "    docs = loader.load()\n",
    "    for d in docs:\n",
    "        documents.append(Document(metadata={\"source\": filepath}, page_content=d.page_content))\n",
    "    SOURCES_DICTIONARY[\"pdf\"] = filepath\n",
    "\n",
    "elif choice == \"2\":\n",
    "    url = input(\"Enter TXT file URL: \")\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        documents.append(Document(metadata={\"source\": url}, page_content=response.text))\n",
    "        SOURCES_DICTIONARY[\"txt_url\"] = url\n",
    "    else:\n",
    "        print(\"Failed to fetch TXT file.\")\n",
    "\n",
    "elif choice == \"3\":\n",
    "    url = input(\"Enter webpage URL: \")\n",
    "    loader = WebBaseLoader(url)\n",
    "    docs = loader.load()\n",
    "    for d in docs:\n",
    "        documents.append(Document(metadata={\"source\": url}, page_content=d.page_content))\n",
    "    SOURCES_DICTIONARY[\"webpage\"] = url\n",
    "\n",
    "elif choice == \"4\":\n",
    "    filepath = input(\"Enter local file path (.txt or .pdf): \")\n",
    "    if filepath.endswith(\".pdf\"):\n",
    "        loader = PyPDFLoader(filepath)\n",
    "    else:\n",
    "        loader = TextLoader(filepath, encoding=\"utf-8\")\n",
    "    docs = loader.load()\n",
    "    for d in docs:\n",
    "        documents.append(Document(metadata={\"source\": filepath}, page_content=d.page_content))\n",
    "    SOURCES_DICTIONARY[\"local_file\"] = filepath\n",
    "\n",
    "else:\n",
    "    print(\"Invalid choice.\")\n",
    "\n",
    "print(\"\\nâœ… Sources Loaded:\", SOURCES_DICTIONARY)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee905411-0361-4a69-98b4-50e8803a35b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------\n",
    "# Step 3: Split Text into Chunks (with metadata preserved)\n",
    "# ------------------------------\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "\n",
    "split_docs = []\n",
    "for doc in documents:\n",
    "    chunks = text_splitter.split_text(doc.page_content)\n",
    "    for chunk in chunks:\n",
    "        split_docs.append(Document(metadata=doc.metadata, page_content=chunk))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a71933-1948-4589-9e5d-6a62ee5e4cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------\n",
    "# Step 4: Create Vector Store with Ollama Embeddings\n",
    "# ------------------------------\n",
    "embeddings = OllamaEmbeddings(model=\"mistral\")  # or \"llama2\", \"nomic-embed-text\", etc.\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=split_docs,       # âœ… pass Document objects, not dicts\n",
    "    embedding=embeddings,\n",
    "    persist_directory=\"./chroma_store\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae8bfa2-8946-4fe2-a46a-488ae07f49be",
   "metadata": {},
   "source": [
    "https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/PWMJ9-Npq9FYNSWrrf99YQ/watsonx.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "62d5c442-8b27-40f2-94d9-6ab0eee5eeac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------\n",
    "# Step 5: Build QA Chain\n",
    "# ------------------------------\n",
    "from langchain_community.llms import Ollama\n",
    "\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 3})\n",
    "llm = Ollama(model=\"mistral\")\n",
    "\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    retriever=retriever,\n",
    "    return_source_documents=True\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "20a9e0e1-0062-4680-9333-68805b318bfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Ask a question (or type 'exit' to quit):  what is moon\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“Œ General Knowledge Answer:\n",
      "  The Moon is a natural satellite that orbits the Earth. It's the fifth largest moon in the solar system and the only celestial body, aside from Earth, to be inhabited by life. It's approximately one-quarter of the size of Earth and has no atmosphere. Its surface is covered with many different types of rock formations that scientists have studied extensively using telescopes on Earth, as well as rovers and landers sent by space agencies from around the world. The Moon plays a significant role in our daily lives, affecting tides due to its gravitational pull, and has been a source of inspiration for humans throughout history.\n",
      "ðŸ”— Sources used: None (general knowledge)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Ask a question (or type 'exit' to quit):  tell me about ibm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“Œ General Knowledge Answer:\n",
      "  IBM (International Business Machines Corporation) is an American multinational technology company headquartered in Armonk, New York. It was founded in 1911 and has a long history of innovation and contribution to the field of computing.\n",
      "\n",
      "IBM is known for its hardware, software, and consulting services. Some of its notable inventions include the floppy disk, the hard disk drive, the magnetic stripe card reader, the relational database, and the UPC barcode scanner.\n",
      "\n",
      "In terms of software, IBM has developed several significant products such as DB2 (a relational database management system), WebSphere (a Java EE-based application server), and Rational Rose (an integrated modeling tool for systems design).\n",
      "\n",
      "IBM's services include IT consulting, cloud services, AI and quantum computing, blockchain, and cybersecurity solutions. The company is also known for its corporate social responsibility efforts, including initiatives in education, the environment, and community development.\n",
      "\n",
      "In recent years, IBM has made significant strides in areas like artificial intelligence (AI), cloud computing, and blockchain technology. For example, Watson, IBM's AI platform, is used in various industries for tasks ranging from healthcare diagnostics to customer service.\n",
      "\n",
      "IBM operates in over 170 countries and employs approximately 350,000 people worldwide. Its corporate slogan is \"IBM: Smarter Planet,\" reflecting its mission to use technology to help make the world smarter, safer, and more efficient.\n",
      "ðŸ”— Sources used: None (general knowledge)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Ask a question (or type 'exit' to quit):  exit\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------\n",
    "# Step 6: Ask Questions\n",
    "# ------------------------------\n",
    "while True:\n",
    "    query = input(\"\\nAsk a question (or type 'exit' to quit): \")\n",
    "    if query.lower() == \"exit\":\n",
    "        break\n",
    "\n",
    "    # Retrieve docs\n",
    "    retrieved_docs = retriever.get_relevant_documents(query)\n",
    "\n",
    "    if retrieved_docs and any(doc.page_content.strip() for doc in retrieved_docs):\n",
    "        result = qa_chain({\"query\": query})\n",
    "\n",
    "        # If context didn't answer the actual question, fallback to Ollama\n",
    "        if query.lower() not in result[\"result\"].lower():\n",
    "            response = llm.invoke(query)\n",
    "            print(\"\\nðŸ“Œ General Knowledge Answer:\\n\", response)\n",
    "            print(\"ðŸ”— Sources used: None (general knowledge)\")\n",
    "        else:\n",
    "            print(\"\\nAnswer from documents:\\n\", result[\"result\"])\n",
    "            print(\"\\nðŸ”— Sources used:\", [doc.metadata.get(\"source\", \"N/A\") for doc in result[\"source_documents\"]])\n",
    "    else:\n",
    "        # No relevant docs, just use Ollama\n",
    "        response = llm.invoke(query)\n",
    "        print(\"\\nðŸ“Œ General Knowledge Answer:\\n\", response)\n",
    "        print(\"ðŸ”— Sources used: None (general knowledge)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d296a9a4-c870-49c9-863d-5f7cce8b6484",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
